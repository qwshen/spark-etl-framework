<?xml version="1.0" encoding="UTF-8" ?>
<etl-pipeline name="event-consolidation" description="This is the process for etl'ing event data" version="1.0.0">
    <settings>
        <singleSparkSession setting="false" />
        <globalViewAsLocal setting="true" />
    </settings>

    <variables>
        <variable name="process_date" value="${events.process_date}" />
        <variable name="staging_uri" value="file:///tmp/staging/events" />
        <variable name="export_dir" value="${events.output_dir}" />
        <variable name="delta_dir" value="/tmp/delta" />
    </variables>

    <aliases>
        <alias name="file-reader" type="com.it21learning.etl.source.FileReader" />
        <alias name="sql" type="com.it21learning.etl.transform.SqlTransformer" />
        <alias name="file-writer" type="com.it21learning.etl.sink.FileWriter" />
        <alias name="delta-writer" type="com.it21learning.etl.sink.DeltaWriter" />
    </aliases>

    <job name="prepare events-features">
        <action name="load users">
            <actor type="file-reader">
                <property name="format">csv</property>
                <property name="options">
                    <option name="header" value="true" />
                </property>
                <property name="path">${events.users_input}</property>
            </actor>
            <output-view name="users" global="true" />
        </action>
        <action name="load train">
            <actor type="file-reader">
                <property name="format">csv</property>
                <property name="options">
                    <option name="header" value="true" />
                </property>
                <property name="path">${events.train_input}</property>
            </actor>
            <output-view name="train" />
        </action>
        <action name="transform users-train">
            <actor type="sql">
                <property name="scriptFile">${application.scripts_uri}/transform-user-train.sql</property>
            </actor>
            <input-views>
                <view name="users" />
                <view name="train" />
            </input-views>
            <output-view name="features" />
        </action>
        <action name="write features">
            <actor type="delta-writer">
                <property name="options">
                    <option name="overwriteSchema" value="true" />
                </property>
                <property name="partitionBy">process_date</property>
                <!-- bucketing only support saveAsTable for the time being -->
                <!--
                    <property name="bucketing">
                        <definition name="numBuckets">6</definition>
                        <definition name="byColumns">user_id</definition>
                    </property>
                -->
                <property name="mode">overwrite</property>
                <property name="sink">
                    <definition name="path">${delta_dir}</definition>
                </property>
                <property name="view">features</property>
            </actor>
            <input-views>
                <view name="features" />
            </input-views>
        </action>
        <action name="create delta-table">
            <actor type="sql">
                <property name="sqlString">create table if not exists features using delta location '${delta_dir}'</property>
            </actor>
        </action>
        <action name="select delta-table">
            <actor type="sql">
                <property name="sqlString">select * from features</property>
            </actor>
            <output-view name="delta_features" />
        </action>
        <action name="write features file">
            <actor type="file-writer">
                <property name="format">csv</property>
                <property name="options">
                    <option name="header" value="true" />
                    <option name="maxRecordsPerFile" value="30000" />
                </property>
                <property name="mode">overwrite</property>
                <property name="path">${export_dir}</property>
                <property name="view">delta_features</property>
            </actor>
            <input-views>
                <view name="delta_features" />
            </input-views>
        </action>
    </job>

    <staging>
        <uri>${staging_uri}</uri>
        <actions all="false">
            <action name="transform users-train" />
        </actions>
    </staging>
</etl-pipeline>