{
    "pipeline-def": {
        "name": "event-consolidation",
        "description": "This is the process for transforming event data",
        "version": "1.0.0",
        "settings": {
            "singleSparkSession": "false",
            "globalViewAsLocal": "true"
        },
        "variables": [
            {
                "name": "process_date",
                "value": "${events.process_date}"
            },
            {
                "name": "staging_uri",
                "value": "file:///tmp/staging/events"
            },
            {
                "name": "file_stream_dir",
                "value": "file:///tmp/file_streaming_result"
            }
        ],
        "aliases": [
            {
                "name": "file-stream-reader",
                "type": "com.it21learning.etl.source.FileStreamReader"
            },
            {
                "name": "sql",
                "type": "com.it21learning.etl.transform.SqlTransformer"
            },
            {
                "name": "file-stream-writer",
                "type": "com.it21learning.etl.sink.FileStreamWriter"
            }
        ],
        "jobs": [
            {
                "name": "prepare events-features",
                "actions": [
                    {
                        "name": "load users",
                        "actor": {
                            "type": "file-stream-reader",
                            "properties": {
                                "format": "csv",
                                "options": {
                                    "header": true,
                                    "delimiter": ",",
                                    "maxFileAge": "16h"
                                },
                                "ddlSchemaString": "user_id string, locale string, birthyear string, gender string, joinedAt string, location string, timezone string",
                                "watermark": {
                                    "timeField": "__timestamp",
                                    "delayThreshold": "5 minutes"
                                },
                                "addTimestamp": true,
                                "fileUri": "${events.users_input}"
                            }
                        },
                        "output-view": {
                            "name": "users"
                        }
                    }
                ]
            }
        ]


    }
}


    <job name="prepare events-features">
        <action name="load train">
            <actor type="file-stream-reader">
                <property name="format">csv</property>
                <property name="options">
                    <option name="header" value="true" />
                    <option name="delimiter" value="," />
                    <option name="maxFileAge" value="9h" />
                </property>
                <property name="ddlSchemaString">user string, event string, invited string, timestamp string, interested string, not_interested string</property>
                <property name="waterMark">
                    <definition name="timeField">__timestamp</definition>
                    <definition name="delayThreshold">5 minutes</definition>
                </property>
                <property name="addTimestamp">true</property>
                <property name="path">${events.train_input}</property>
            </actor>
            <output-view name="train" />
        </action>
        <action name="transform users-train">
            <actor type="sql">
                <property name="scriptFile">${application.scripts_uri}/stream-user-train.sql</property>
            </actor>
            <input-views>
                <view name="users" />
                <view name="train" />
            </input-views>
            <output-view name="features" />
        </action>
        <action name="write features">
            <actor type="file-stream-writer">
                <property name="format">csv</property>
                <property name="options">
                    <option name="header" value="true" />
                    <option name="maxRecordsPerFile" value="30000" />
                    <option name="checkpointLocation" value="/tmp/file_streaming_checkpoint" />
                </property>
                <property name="trigger">
                    <definition name="mode">processingTime</definition>
                    <definition name="interval">60 seconds</definition>
                </property>
                <property name="partitionBy">invited</property>
                <property name="outputMode">append</property>
                <property name="waitTimeInMs">16000</property>
                <property name="path">${file_stream_dir}</property>
                <property name="view">features</property>
            </actor>
            <input-views>
                <view name="features" />
            </input-views>
        </action>
    </job>

    <staging>
        <uri>${staging_uri}</uri>
        <actions all="false">
            <action name="transform users-train" />
        </actions>
    </staging>
</etl-pipeline>